# Can you explain your work hard/smart answer above?
There is true synergy which blooms from working smart in tandem with working hard. You will maximize your potential if you work smart then hard. If you work hard but not smart, you run the risk of wasting time & energy. You will need to fail to learn from your mistakes, and the faster you fail and recover, the faster you can learn from your mistakes and continue to grow. If you are working hard while not learning from your mistakes, you are wasting large portions of energy. On the contrary, if you work smart, but not hard, then you are limiting your self of your true potential, and may never realize success or what lies beyond perceived success, as a consequence. I have lived by the motto: "Things that are worth doing in life are not easy". It would be smart to choose work with which to live a worthwhile life. 

# Describe 1-3 projects you worked on and describe in as much detail as possible the technical steps you took to take the project to completion from beginning to end.
1) I built a robot to sort washers for the Clemson Senior Design Competition with a team of electrical and computer engineering students. We created a bill of materials, sketched potential designs, and built and tested the robot. We implemented a Quanser Q4 board power supply, a webcam, a wheatsone bridge, and a rotational disk & electromagnet which were controlled by an Arduino microcontroller and driven by separate electric motors. I personally wrote the code to drive the electric motor that spun the disk. I wrote the code to detect the washers using openCV and Matlab. I performed object detection by using a mask to filter out the white background of the disk. Then I would calculate the centroids of the washers to count them and determine their orientation. I would next determine how many steps to rotate the electric motor to align a desired washer with the electromagnet. Each washer would be picked up and weighed before being sorted in a predefined pattern that a user specified on a Matlab GUI. We implemented an E-stop for emergencies, and developed an efficient and safe solution that sorted the washers faster than any other team with no serious injuries.

2) I recently completed a Capstone project with an MIT Applied Data Science Program. In this project I used transfer learning on the EfficientNetV2 model to detect whether an image of a face was happy, sad, surprised, or neutral. I examined and cleaned the dataset of images that were not of faces or that were corrupt. Then I performed data augmentation on the dataset. I rotated the images, flipped them over the horizontal axis, rescaled the images, and zoomed in on them to make the data more robust and thereby increase the predictive accuracy of the model. I split the dataset into training, testing, and validation sets to validate the accuracy of the models that I built. I first created a model based off of the VGG16 architecture. I pulled a layer from this architecture, marked the layer as "non-trainable", and flatted the layer before adding a dense layer with a relu activation function. This dense layer would then feed into a dense layer with 4 neurons and a softmax activation function where each neuron was a predicted category of emotion of a face in the dataset. I implemented callbacks such as "early_stopping"  and "ReduceLROnPlateau" to stop the model if it became overfit so as to not waste resources and to reduce the learning rate upon a plateau to keep improving the model performance. I compiled the model, trained the model for 5 epochs, and tested the model. It had a 44% base accuracy. 

I next chose to create an EfficientNet model because EfficientNet is known for its performance on the ImageNet dataset as this was pertinent to the problem. It is also known for its accuracy and efficiency. I selected the penultimate block of the EfficientNet model (since the model was already trained sufficiently to recognize features in a variety of images) and trained this block on the dataset specific to this problem. I used GlobalMaxPool2D to identify the strongest features of an image. This allowed the model to leverage the ability to recognize general features from the non-trainable layers while simultaneously detecting the features that are specific to the new dataset with precision. After training and testing the model, the predictive accuracy increased by over a factor of two from the base EfficientNetV2 model and achieved a predictive accuracy of approximately 60% on this real-world dataset. The model was trained frugally with limited time and processing power yet still achieved this predictive capability. 

3) I created a Twitter bot to make people that are #depressed feel better. I used the Twitter API to pull an arbitrary number of tweets containing the hashtag "depressed". Next, I classified whether the tweets were of positive or negative sentiment by using a logistic regression model that I trained for sentiment analysis of tweets. Of the "negative" sentiment tweets, I pulled tweets that were historically liked by a user of a negative #depressed tweet and classified each liked tweet with a stochastic gradient descent classifier that was trained on a labeled dataset of quotes. Each quote is associated with one of ten topics: death, happiness, inspiration, love, poetry, romance, science, success, time, & truth. Once each liked tweet was classified by one of these topics, the mode of the classes was identified to be the class that the individual liked the most. I would then use this class to suggest a tweet to the individual by creating a cosine similarity matrix that contains the original depressed tweet and a list of quotes that are of the same class that the individual likes most. This would identify which quote would be most relevant to what the user had tweeted. This technique created a flurry of likes and I plotted and documented the response to this technique. It was rewarding to see people who are depressed feel good for a moment.

# Describe the tasks you see yourself doing as part of this position. I value good organization and attention to detail.
I would love to make weekly videos about developing radial menus for Spot. They could be augmented reality apps that could target objects in a space and allow the user to select different actions for spot to do based upon the object that is selected. 

I would also love to create a roomba-esque lawn mower robot that implemented computer vision and 3D mapping to autonomously mow my lawn. It could identify grass and non-grass in real time, identify objects and people, and, at the end of its mission, "park itself" for charging in a solar "doggy shed" and charge using inductive resonance. It could be put on a cycle to mow periodically, and I would love to document the process of building this and share that with the world!

# Tell me why you want to work with me and how you can help make awesome stuff.
